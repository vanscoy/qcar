{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "InT7_Hnn-_4-"
   },
   "source": [
    "# Using YOLOv4 and OpenCV 4 to detect custom objects (Traffic Road Signs)\n",
    "\n",
    "I wanted to try to use OpenCV and YoloV4 in order to detect to detect custom objects (Traffic Road Signs), this is what this notebook will be about.\n",
    "\n",
    "*Thank you Joseph Redmon and Ali Farhadi for their incredible work on **YOLO object detector** : **[YOLOv3: An Incremental Improvement](https://arxiv.org/abs/1804.02767)**, *Redmon, Joseph and Farhadi, Ali* ; arXiv, 2018.\n",
    "\n",
    "*Thank you AlexeyAB for your* **[YOLOv4 : Algorithm](https://github.com/AlexeyAB/darknet)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VgFkipuK-_5E"
   },
   "outputs": [],
   "source": [
    "# import useful libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from yolo_utils import *\n",
    "\n",
    "print('OpenCV version : ', cv2. __version__)\n",
    "print(cv2.cuda.getCudaEnabledDeviceCount())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J011UaOx-_5H"
   },
   "source": [
    "### Load YoloV4 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6lNsDmSE-_5I",
    "outputId": "9915621d-8c15-417f-ea2e-93befabc392c"
   },
   "outputs": [],
   "source": [
    "# load the obj/classes names\n",
    "obj_file = './data/obj.names'\n",
    "classNames = read_classes(obj_file)\n",
    "print(\"Classes' names :\\n\", classNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "17jo_5tzLNiZ"
   },
   "source": [
    "### YoloV4 weights and cfg files\n",
    "\n",
    "In this part we'll upload YoloV3 Weights and cfg files in order to input them into ***cv2.dnn.readNetFromDarknet()*** and build our forward propagation with OpenCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 263
    },
    "id": "sYmLADJ2LNSA",
    "outputId": "aba64119-7ff5-4336-a35f-acc1016a9800"
   },
   "outputs": [],
   "source": [
    "# load the model config and weights\n",
    "modelConfig_path = './cfg/yolov4-rds.cfg'\n",
    "modelWeights_path = './weights/yolov4-rds_last.weights'\n",
    "\n",
    "# read the model cfg and weights with the cv2 DNN module\n",
    "neural_net = cv2.dnn.readNetFromDarknet(modelConfig_path, modelWeights_path)\n",
    "# set the preferable Backend to GPU for performing faster\n",
    "neural_net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "neural_net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on video files\n",
    "\n",
    "These blocks will run object detection on videos in our **'/inputs/video/[ClassesNames]/'**  folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# confidence and non-max suppression threshold for this YoloV3 version\n",
    "confidenceThreshold = 0.5\n",
    "nmsThreshold = 0.1\n",
    "\n",
    "# defining the input frame resolution for the neural network to process\n",
    "# we can decrease the height and width but the minimum is 320x320.\n",
    "network = neural_net\n",
    "height, width = 320,320\n",
    "\n",
    "# load the video\n",
    "cap_video = load_video('/traffic-lights/traffic_light_test6.mp4')\n",
    "\n",
    "# save the video with object detections\n",
    "frame_width = int(cap_video.get(3))\n",
    "frame_height = int(cap_video.get(4))\n",
    "video_frames_save = cv2.VideoWriter('./results/videos/resultvidcolab6.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 25, (frame_width,frame_height))\n",
    "\n",
    "while cap_video.isOpened():\n",
    "    success, video_frames = cap_video.read()\n",
    "    # if 'video_frames' is read correctly 'success' is True\n",
    "    if not success:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "        \n",
    "    # using convert_to_blob function : \n",
    "    outputs = convert_to_blob(video_frames, network, height, width)    \n",
    "    # apply object detection on the video file\n",
    "    bounding_boxes, class_objects, confidence_probs = object_detection(outputs, video_frames, confidenceThreshold)   \n",
    "    # perform non-max suppression\n",
    "    indices = nms_bbox(bounding_boxes, confidence_probs, confidenceThreshold, nmsThreshold)\n",
    "    # draw the boxes\n",
    "    box_drawing(video_frames, indices, bounding_boxes, class_objects, confidence_probs, classNames, color=(0,255,255), thickness=2)\n",
    "  \n",
    "    # save the video\n",
    "    video_frames_save.write(video_frames)\n",
    "    \n",
    "    cv2.imshow('Object Detection in videos', video_frames)         \n",
    "    \n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap_video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "yolov3_ftn4.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
